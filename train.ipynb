{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda:0')\n",
    "EPOCHS = 2000\n",
    "LEARNING_RATE = 0.0003\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size=3, hidden_size=128, num_layers=2, bias=False, batch_first=True)\n",
    "        self.linear1 = nn.Linear(128, 64, bias=True)\n",
    "        self.linear2 = nn.Linear(64, 1, bias=True)\n",
    "        self.norm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rnn(x)[0][:,-1,:]\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        out = self.norm(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, raw_data, device='cpu') -> None:\n",
    "        super().__init__()\n",
    "        self.raw_data = raw_data\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.raw_data[index, :, :-1]).float().to(self.device)\n",
    "        y = torch.tensor(self.raw_data[index, :, -1][0]).float().unsqueeze(-1).to(self.device)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "raw_data = np.load('dataset.npy')\n",
    "dataset = MyDataset(raw_data, device=DEVICE)\n",
    "train_set, validation_set = random_split(dataset, [0.8, 0.2])\n",
    "train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_set, batch_size=len(validation_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryF1Score, BinaryAccuracy, BinaryPrecision, BinaryRecall\n",
    "from torchmetrics.functional.classification import binary_accuracy, binary_precision, binary_recall, binary_f1_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    x, y = next(iter(dataloader))\n",
    "    preds = model(x)\n",
    "    loss = loss_fn(preds, y)\n",
    "    accuracy = binary_accuracy(preds.cpu(), y.cpu())\n",
    "    precision = binary_precision(preds.cpu(), y.cpu())\n",
    "    recall = binary_recall(preds.cpu(), y.cpu())\n",
    "    f1 = binary_f1_score(preds.cpu(), y.cpu())\n",
    "    return loss.cpu().item(), accuracy, precision, recall, f1\n",
    "\n",
    "model = Model().to(DEVICE)\n",
    "loss_fn = nn.BCELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "metric_accuracy = BinaryAccuracy().to(DEVICE)\n",
    "metric_precision = BinaryPrecision().to(DEVICE)\n",
    "metric_recall = BinaryRecall().to(DEVICE)\n",
    "metric_f1 = BinaryF1Score().to(DEVICE)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for i in tqdm(range(EPOCHS), desc='Training epochs'):\n",
    "    model.train()\n",
    "    ep_loss = []\n",
    "    for mb_x, mb_y in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "        out = model(mb_x)\n",
    "        loss = loss_fn(out, mb_y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        ep_loss.append(loss.cpu().item())\n",
    "        metric_accuracy(out, mb_y)\n",
    "        metric_f1(out, mb_y)\n",
    "        metric_precision(out, mb_y)\n",
    "        metric_recall(out, mb_y)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        torch.save(model.state_dict(), f\"./models/{i + 1}_model.pt\")\n",
    "\n",
    "    v_loss, v_acc, v_pre, v_rec, v_f1 = validate(model, validation_dataloader)\n",
    "    writer.add_scalars('Loss', {'train': np.mean(ep_loss), 'validation': v_loss}, i)\n",
    "    writer.add_scalars('Metric/Accuracy', {'train': metric_accuracy.compute(), 'validation': v_acc}, i)\n",
    "    writer.add_scalars('Metric/Precision', {'train': metric_precision.compute(), 'validation': v_pre}, i)\n",
    "    writer.add_scalars('Metric/Recall', {'train': metric_recall.compute(), 'validation': v_rec}, i)\n",
    "    writer.add_scalars('Metric/F1', {'train': metric_f1.compute(), 'validation': v_f1}, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
