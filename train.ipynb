{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda:0')\n",
    "EPOCHS = 2000\n",
    "LEARNING_RATE = 0.0003\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size=3, hidden_size=128, num_layers=2, bias=False, batch_first=True)\n",
    "        self.linear1 = nn.Linear(128, 64, bias=True)\n",
    "        self.linear2 = nn.Linear(64, 1, bias=True)\n",
    "        self.norm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rnn(x)[0][:,-1,:]\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        out = self.norm(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, raw_data, device='cpu') -> None:\n",
    "        super().__init__()\n",
    "        self.raw_data = raw_data\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.raw_data[index, :, :-1]).float().to(self.device)\n",
    "        y = torch.tensor(self.raw_data[index, :, -1][0]).float().unsqueeze(-1).to(self.device)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "raw_data = np.load('dataset.npy')\n",
    "dataset = MyDataset(raw_data, device=DEVICE)\n",
    "train_set, validation_set = random_split(dataset, [0.8, 0.2])\n",
    "train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_set, batch_size=len(validation_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  70%|███████   | 1402/2000 [12:37<05:23,  1.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m ep_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     40\u001b[0m metric_accuracy(out, mb_y)\n\u001b[1;32m---> 41\u001b[0m metric_f1(out, mb_y)\n\u001b[0;32m     42\u001b[0m metric_precision(out, mb_y)\n\u001b[0;32m     43\u001b[0m metric_recall(out, mb_y)\n",
      "File \u001b[1;32mc:\\Users\\halo9\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\halo9\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torchmetrics\\metric.py:298\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_reduce_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    300\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\halo9\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torchmetrics\\metric.py:367\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    368\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[0;32m    370\u001b[0m \u001b[39m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\halo9\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torchmetrics\\metric.py:457\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[0;32m    456\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m         update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    458\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    459\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\halo9\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:183\u001b[0m, in \u001b[0;36mBinaryStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    181\u001b[0m     _binary_stat_scores_tensor_validation(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultidim_average, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_index)\n\u001b[0;32m    182\u001b[0m preds, target \u001b[39m=\u001b[39m _binary_stat_scores_format(preds, target, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_index)\n\u001b[1;32m--> 183\u001b[0m tp, fp, tn, fn \u001b[39m=\u001b[39m _binary_stat_scores_update(preds, target, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultidim_average)\n\u001b[0;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_state(tp, fp, tn, fn)\n",
      "File \u001b[1;32mc:\\Users\\halo9\\anaconda3\\envs\\torch_gpu\\lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:127\u001b[0m, in \u001b[0;36m_binary_stat_scores_update\u001b[1;34m(preds, target, multidim_average)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the statistics.\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m sum_dim \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m multidim_average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mglobal\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m [\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 127\u001b[0m tp \u001b[39m=\u001b[39m ((target \u001b[39m==\u001b[39m preds) \u001b[39m&\u001b[39m (target \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39msum(sum_dim)\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m    128\u001b[0m fn \u001b[39m=\u001b[39m ((target \u001b[39m!=\u001b[39m preds) \u001b[39m&\u001b[39m (target \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39msum(sum_dim)\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m    129\u001b[0m fp \u001b[39m=\u001b[39m ((target \u001b[39m!=\u001b[39m preds) \u001b[39m&\u001b[39m (target \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m))\u001b[39m.\u001b[39msum(sum_dim)\u001b[39m.\u001b[39msqueeze()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import BinaryF1Score, BinaryAccuracy, BinaryPrecision, BinaryRecall\n",
    "from torchmetrics.functional.classification import binary_accuracy, binary_precision, binary_recall, binary_f1_score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    x, y = next(iter(dataloader))\n",
    "    preds = model(x)\n",
    "    loss = loss_fn(preds, y)\n",
    "    accuracy = binary_accuracy(preds.cpu(), y.cpu())\n",
    "    precision = binary_precision(preds.cpu(), y.cpu())\n",
    "    recall = binary_recall(preds.cpu(), y.cpu())\n",
    "    f1 = binary_f1_score(preds.cpu(), y.cpu())\n",
    "    return loss.cpu().item(), accuracy, precision, recall, f1\n",
    "\n",
    "model = Model().to(DEVICE)\n",
    "loss_fn = nn.BCELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "metric_accuracy = BinaryAccuracy().to(DEVICE)\n",
    "metric_precision = BinaryPrecision().to(DEVICE)\n",
    "metric_recall = BinaryRecall().to(DEVICE)\n",
    "metric_f1 = BinaryF1Score().to(DEVICE)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for i in tqdm(range(EPOCHS), desc='Training epochs'):\n",
    "    model.train()\n",
    "    ep_loss = []\n",
    "    for mb_x, mb_y in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "        out = model(mb_x)\n",
    "        loss = loss_fn(out, mb_y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        ep_loss.append(loss.cpu().item())\n",
    "        metric_accuracy(out, mb_y)\n",
    "        metric_f1(out, mb_y)\n",
    "        metric_precision(out, mb_y)\n",
    "        metric_recall(out, mb_y)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        torch.save(model.state_dict(), f\"./models/{i + 1}_model.pt\")\n",
    "\n",
    "    v_loss, v_acc, v_pre, v_rec, v_f1 = validate(model, validation_dataloader)\n",
    "    writer.add_scalars('Loss', {'train': np.mean(ep_loss), 'validation': v_loss}, i)\n",
    "    writer.add_scalars('Metric/Accuracy', {'train': metric_accuracy.compute(), 'validation': v_acc}, i)\n",
    "    writer.add_scalars('Metric/Precision', {'train': metric_precision.compute(), 'validation': v_pre}, i)\n",
    "    writer.add_scalars('Metric/Recall', {'train': metric_recall.compute(), 'validation': v_rec}, i)\n",
    "    writer.add_scalars('Metric/F1', {'train': metric_f1.compute(), 'validation': v_f1}, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
